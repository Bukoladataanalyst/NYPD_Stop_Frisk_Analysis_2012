{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454043d6",
   "metadata": {},
   "source": [
    "#........PREDICTIVE MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8ff3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L.....LIBRARY IMPORTATON\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2edd3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#......READ CLEANED CSV\n",
    "\n",
    "df=pd.read_csv(\"C:\\\\SAIT\\\\DATA 475\\\\Projt\\\\SQF_2012_cleaned.csv\",dtype=str,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df2700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....Collecting all grop of Prefix for eassy access\n",
    "def cols_starting(prefix):\n",
    "    return [c for c in df.columns if c.startswith(prefix)]\n",
    "\n",
    "def exists(col):\n",
    "    return col in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....Defining Targets.....DATA PREPARATION PART\n",
    "\n",
    "# T1: any use of force (create from pf_* columns)\n",
    "pf_cols = cols_starting(\"pf_\")\n",
    "df[\"any_force\"] = (df[pf_cols].fillna(0).astype(float).sum(axis=1) > 0).astype(int) if pf_cols else np.nan\n",
    "\n",
    "# T2: weapon_found\n",
    "has_weapon = exists(\"weapon_found\")\n",
    "\n",
    "#T3: handcuff used\n",
    "has_hcuff = exists(\"pf_hcuff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660047a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#....CREATING PREDICTOR(X) FEATURES AND TARGET(Y) VARIABLES....DESCRIBE FINAL DATASET USED\n",
    "\n",
    "num_cols  = [c for c in [\"age\",\"precinct\",\"hour\"] if exists(c)]\n",
    "cat_cols  = [c for c in [\"sex\",\"race\",\"time_of_day\",\"weekday\"] if exists(c)]\n",
    "flag_cols = cols_starting(\"cs_\")                    # 0/1 reason flags\n",
    "extra_num = [c for c in [\"crimsusp_encoded\"] if exists(c)]\n",
    "\n",
    "X_base = num_cols + cat_cols + flag_cols + extra_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_for_target(target_col, drop_from_X_prefixes=None, positive_label_name=None):\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"TARGET: {target_col}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    if not exists(target_col):\n",
    "        print(f\"!! Skipping: '{target_col}' not found.\")\n",
    "        return\n",
    "\n",
    "    # ---- Build X ( drop any leaking prefixes) ----REMOVING VARIABLES NOT NEEDED FOR THE ANALYSIS\n",
    "    X_cols = X_base.copy()\n",
    "    for pre_drop in (drop_from_X_prefixes or []):\n",
    "        X_cols = [c for c in X_cols if not c.startswith(pre_drop)]\n",
    "\n",
    "    # ---- Keep rows with the target; then fill NaNs in predictors ----\n",
    "    data = df[X_cols + [target_col]].dropna(subset=[target_col]).copy()\n",
    "    data = data.fillna({\n",
    "        c: (data[c].median() if data[c].dtype != 'object'\n",
    "            else data[c].mode().iloc[0])\n",
    "        for c in data.columns if data[c].isna().any()\n",
    "    })\n",
    "\n",
    "    X = data[X_cols]\n",
    "    y = data[target_col].astype(int)\n",
    "\n",
    "    # ---- Preprocess: scale numerics, one-hot categoricals, passthrough flags ----\n",
    "    num_cols = [c for c in X_cols if c in (['age','precinct','hour'] + [c for c in df.columns if c.endswith('_num')])]\n",
    "    cat_cols = [c for c in X_cols if c in ['sex','race','time_of_day','weekday']]\n",
    "    flag_cols = [c for c in X_cols if c.startswith('cs_')] # already 0/1\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), [c for c in X_cols if c in num_cols]),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [c for c in X_cols if c in cat_cols]),\n",
    "            (\"pas\", \"passthrough\", [c for c in X_cols if c in flag_cols]),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    # ---- Models ----THREE(3) DIFFERENT MODELS CREATED\n",
    "    models = {\n",
    "        \"LogReg\": LogisticRegression(max_iter=200, n_jobs=None),\n",
    "        \"RandForest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=15),\n",
    "    }\n",
    "\n",
    "    # ---- Train/test split ----\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    # ---- Fit & evaluate ----\n",
    "    results = []\n",
    "    for name, clf in models.items():\n",
    "        pipe = Pipeline(steps=[(\"pre\", pre), (\"clf\", clf)])\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        proba = pipe.predict_proba(X_te)[:, 1] if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\") else None\n",
    "        pred = pipe.predict(X_te)\n",
    "\n",
    "##....ASSESSING MODEL PERFORMANCES\n",
    "\n",
    "        acc = accuracy_score(y_te, pred)\n",
    "        prec = precision_score(y_te, pred, zero_division=0)\n",
    "        rec = recall_score(y_te, pred, zero_division=0)\n",
    "        f1 = f1_score(y_te, pred, zero_division=0)\n",
    "        auc = roc_auc_score(y_te, proba) if proba is not None else np.nan\n",
    "        results.append((name, acc, prec, rec, f1, auc))\n",
    "\n",
    "        print(f\"\\n– {name} –\")\n",
    "        print(f\"Accuracy={acc:.3f} Precision={prec:.3f} Recall={rec:.3f} F1={f1:.3f} ROC-AUC={auc:.3f}\")\n",
    "        print(\"Confusion matrix:\\n\", confusion_matrix(y_te, pred))\n",
    "        print(classification_report(y_te, pred, digits=3))\n",
    "\n",
    "    res_df = pd.DataFrame(results, columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"ROC_AUC\"])\n",
    "    pd.set_option(\"display.max_rows\",20)\n",
    "    print(\"\\nSummary:\\n\", res_df.sort_values(\"F1\", ascending=False))\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1831179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TARGET: any_force\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "– LogReg –\n",
      "Accuracy=0.827 Precision=0.522 Recall=0.004 F1=0.007 ROC-AUC=0.633\n",
      "Confusion matrix:\n",
      " [[110134     76]\n",
      " [ 22935     83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.828     0.999     0.905    110210\n",
      "           1      0.522     0.004     0.007     23018\n",
      "\n",
      "    accuracy                          0.827    133228\n",
      "   macro avg      0.675     0.501     0.456    133228\n",
      "weighted avg      0.775     0.827     0.750    133228\n",
      "\n",
      "\n",
      "– RandForest –\n",
      "Accuracy=0.829 Precision=0.515 Recall=0.197 F1=0.285 ROC-AUC=0.725\n",
      "Confusion matrix:\n",
      " [[105949   4261]\n",
      " [ 18492   4526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.961     0.903    110210\n",
      "           1      0.515     0.197     0.285     23018\n",
      "\n",
      "    accuracy                          0.829    133228\n",
      "   macro avg      0.683     0.579     0.594    133228\n",
      "weighted avg      0.793     0.829     0.796    133228\n",
      "\n",
      "\n",
      "– KNN –\n",
      "Accuracy=0.824 Precision=0.427 Recall=0.050 F1=0.090 ROC-AUC=0.650\n",
      "Confusion matrix:\n",
      " [[108658   1552]\n",
      " [ 21862   1156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.986     0.903    110210\n",
      "           1      0.427     0.050     0.090     23018\n",
      "\n",
      "    accuracy                          0.824    133228\n",
      "   macro avg      0.630     0.518     0.496    133228\n",
      "weighted avg      0.762     0.824     0.762    133228\n",
      "\n",
      "\n",
      "Summary:\n",
      "         Model  Accuracy  Precision    Recall        F1   ROC_AUC\n",
      "1  RandForest  0.829218   0.515079  0.196629  0.284609  0.724757\n",
      "2         KNN  0.824256   0.426883  0.050222  0.089870  0.649780\n",
      "0      LogReg  0.827281   0.522013  0.003606  0.007162  0.632695\n",
      "        Model  Accuracy  Precision    Recall        F1   ROC_AUC\n",
      "0      LogReg  0.827281   0.522013  0.003606  0.007162  0.632695\n",
      "1  RandForest  0.829218   0.515079  0.196629  0.284609  0.724757\n",
      "2         KNN  0.824256   0.426883  0.050222  0.089870  0.649780\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TARGET: pf_hcuff\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "– LogReg –\n",
      "Accuracy=0.964 Precision=0.000 Recall=0.000 F1=0.000 ROC-AUC=0.706\n",
      "Confusion matrix:\n",
      " [[128415      1]\n",
      " [  4812      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     1.000     0.982    128416\n",
      "           1      0.000     0.000     0.000      4812\n",
      "\n",
      "    accuracy                          0.964    133228\n",
      "   macro avg      0.482     0.500     0.491    133228\n",
      "weighted avg      0.929     0.964     0.946    133228\n",
      "\n",
      "\n",
      "– RandForest –\n",
      "Accuracy=0.963 Precision=0.446 Recall=0.062 F1=0.109 ROC-AUC=0.736\n",
      "Confusion matrix:\n",
      " [[128046    370]\n",
      " [  4514    298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.997     0.981    128416\n",
      "           1      0.446     0.062     0.109      4812\n",
      "\n",
      "    accuracy                          0.963    133228\n",
      "   macro avg      0.706     0.530     0.545    133228\n",
      "weighted avg      0.947     0.963     0.950    133228\n",
      "\n",
      "\n",
      "– KNN –\n",
      "Accuracy=0.964 Precision=0.000 Recall=0.000 F1=0.000 ROC-AUC=0.643\n",
      "Confusion matrix:\n",
      " [[128414      2]\n",
      " [  4812      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     1.000     0.982    128416\n",
      "           1      0.000     0.000     0.000      4812\n",
      "\n",
      "    accuracy                          0.964    133228\n",
      "   macro avg      0.482     0.500     0.491    133228\n",
      "weighted avg      0.929     0.964     0.946    133228\n",
      "\n",
      "\n",
      "Summary:\n",
      "         Model  Accuracy  Precision    Recall        F1   ROC_AUC\n",
      "1  RandForest  0.963341   0.446108  0.061929  0.108759  0.736156\n",
      "0      LogReg  0.963874   0.000000  0.000000  0.000000  0.706166\n",
      "2         KNN  0.963866   0.000000  0.000000  0.000000  0.642674\n",
      "        Model  Accuracy  Precision    Recall        F1   ROC_AUC\n",
      "0      LogReg  0.963874   0.000000  0.000000  0.000000  0.706166\n",
      "1  RandForest  0.963341   0.446108  0.061929  0.108759  0.736156\n",
      "2         KNN  0.963866   0.000000  0.000000  0.000000  0.642674\n"
     ]
    }
   ],
   "source": [
    "#...Calling the function\n",
    "\n",
    "res_force = run_models_for_target(\n",
    "    target_col=\"any_force\",\n",
    "    drop_from_X_prefixes=[\"pf_\"],\n",
    "    positive_label_name=\"force used\"\n",
    ")\n",
    "print(res_force)\n",
    "\n",
    "if \"weapon_found\" in df.columns:\n",
    "    res_weapon = run_models_for_target(\n",
    "        target_col=\"weapon_found\",\n",
    "        drop_from_X_prefixes=None,\n",
    "        positive_label_name=\"weapon found\"\n",
    "    )\n",
    "    print(res_weapon)\n",
    "\n",
    "if \"pf_hcuff\" in df.columns:\n",
    "    res_hcuff = run_models_for_target(\n",
    "        target_col=\"pf_hcuff\",\n",
    "        drop_from_X_prefixes=[\"pf_\"],\n",
    "        positive_label_name=\"handcuff used\"\n",
    "    )\n",
    "    print(res_hcuff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
